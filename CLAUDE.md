# Knowledge Graph System - Claude Development Guide

## Project Overview

A multi-dimensional knowledge extraction system that transforms documents into interconnected concept graphs using Apache AGE (PostgreSQL graph extension), enabling semantic exploration beyond sequential reading.

**Platform Architecture (Fully Containerized):**

The system runs entirely in Docker containers - **no local Python installation required**. Configure secrets once, start infrastructure, configure through operator container.

**Five Core Containers:**
1. **knowledge-graph-postgres** - Apache AGE (PostgreSQL 16) graph database
2. **kg-api-dev** - Python FastAPI REST API server (ingestion + queries)
3. **kg-operator** - Platform configuration container (admin, AI providers, API keys)
4. **knowledge-graph-garage** - S3-compatible object storage (Garage)
5. **kg-web-dev** - React visualization web app (Next.js)

**Optional Local Clients:**
- **kg CLI** - TypeScript command-line interface (optional, for local operations)
- **MCP Server** - Model Context Protocol server for Claude Desktop integration

**Workflow:**
```
1. Generate secrets:  ./operator/lib/init-secrets.sh --dev
2. Start infra:       ./operator/lib/start-infra.sh
3. Configure via operator container (no local Python needed)
4. Start apps:        ./operator/lib/start-app.sh
5. Use kg CLI or web UI
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Containers                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Documents â†’ [API Container] â†’ LLM Extraction â†’ [Postgres]  â”‚
â”‚                      â†“                               â†“      â”‚
â”‚              [Garage S3 Storage]         [Apache AGE Graph] â”‚
â”‚                      â†“                               â†“      â”‚
â”‚               [Web Container] â† REST API â† [API Container]  â”‚
â”‚                                                             â”‚
â”‚  Configuration: [Operator Container] â†’ [Postgres Config]    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†‘
                   kg CLI (optional)
                   MCP Server (optional)
```

**Tech Stack:**
- Python 3.11+ FastAPI (REST API server + ingestion pipeline)
- Apache AGE / PostgreSQL 16 (graph database using openCypher)
- TypeScript/Node.js (CLI + MCP client - optional local tools)
- React/Next.js (web visualization)
- Garage (S3-compatible object storage)
- Docker Compose (infrastructure orchestration)
- OpenAI/Anthropic/Ollama APIs (LLM providers)

**Query Language:**
- **openCypher:** Open-source graph query language implemented by Apache AGE
- **ISO/IEC 39075:2024 GQL:** Standardized graph query language based on openCypher
- **Important:** AGE uses openCypher, not Neo4j's proprietary Cypher implementation
  - This explains syntax differences (e.g., no `ON CREATE SET` / `ON MATCH SET`)
  - See ADR-016 "openCypher Compatibility" section for details

## Important Files & Directories

### Configuration
- `.env` - Infrastructure secrets (generated by `init-secrets.sh`, never edit manually)
- `.env.example` - Configuration template
- `docker/docker-compose.yml` - All container definitions
- `schema/init.sql` - Apache AGE baseline schema
- `schema/migrations/` - Database migration files

### Core Code (API Server)
- `src/api/main.py` - FastAPI application entry point
- `src/api/lib/ai_providers.py` - Modular AI provider abstraction
- `src/api/lib/llm_extractor.py` - LLM concept extraction
- `src/api/lib/age_client.py` - Apache AGE database operations
- `src/api/lib/ingestion.py` - Ingestion pipeline
- `src/api/routes/` - REST API endpoints (queries, jobs, ontology, admin)

### Core Code (TypeScript Client)
- `client/src/index.ts` - Unified CLI entry point
- `client/src/cli/` - CLI command implementations
- `client/src/api/client.ts` - REST API client
- `client/install.sh` - Installs `kg` command globally

### Core Code (Web App)
- `web/` - React/Next.js visualization application

### Operator (Platform Management)
- `operator/configure.py` - Main configuration CLI (runs in operator container)
- `operator/lib/init-secrets.sh` - Generate infrastructure secrets
- `operator/lib/start-infra.sh` - Start postgres + garage + operator
- `operator/lib/start-app.sh` - Start API + web app
- `operator/lib/stop.sh` - Stop all services
- `operator/lib/teardown.sh` - Complete teardown with options
- `operator/admin/` - Admin utilities and management scripts
- `operator/diagnostics/` - Diagnostic and maintenance tools

### Development Tools (Local)
- `scripts/development/test/` - Unit and integration test scripts
- `client/` - TypeScript kg CLI and MCP server source code

### Documentation
- `docs/README.md` - Documentation index
- `docs/architecture/ARCHITECTURE.md` - System design
- `docs/architecture/ADR-*.md` - Architecture Decision Records
- `docs/guides/QUICKSTART.md` - Getting started guide

## Development Workflow

### Initial Setup (First Time)

The system uses the **operator architecture (ADR-061)** where all configuration is managed through a dedicated operator container. **No local Python installation required** - everything runs in containers.

**Prerequisites:**
- Docker or Podman
- Docker Compose or Podman Compose
- Node.js + npm (to install kg CLI for convenient local operations)

**Setup Steps:**

```bash
# 1. Generate infrastructure secrets (encryption keys, database password, OAuth signing key)
#    Modes: --dev (weak passwords allowed) or --prod (enforces strong passwords)
./operator/lib/init-secrets.sh --dev

# 2. Start infrastructure (postgres + garage + operator containers)
#    Auto-applies database migrations
./operator/lib/start-infra.sh

# 3. Configure admin user (runs in operator container - no local Python needed)
docker exec -it kg-operator python /workspace/operator/configure.py admin

# 4. Configure AI extraction provider
docker exec kg-operator python /workspace/operator/configure.py ai-provider openai --model gpt-4o

# 5. Configure embedding provider (list options, then activate)
docker exec kg-operator python /workspace/operator/configure.py embedding
docker exec kg-operator python /workspace/operator/configure.py embedding 2  # Activate profile ID 2

# 6. Store API keys (encrypted in database)
docker exec -it kg-operator python /workspace/operator/configure.py api-key openai

# 7. Start application containers (API + web app)
./operator/lib/start-app.sh

# 8. Install kg CLI globally for convenient local operations
cd client && ./install.sh && cd ..

# 9. Verify system is ready
kg health
kg database stats
```

**That's it!** No venv, no pip install, no local Python setup. Everything runs in containers.

**Using the Platform:**
- **kg CLI** (recommended) - Fast, convenient command-line interface for all operations
- **Web UI** - Interactive graph visualization at http://localhost:3000
- **Direct API** - REST endpoints at http://localhost:8000 (see /docs for OpenAPI)

### Daily Development

**Starting Services:**
```bash
# Start infrastructure if not running
./operator/lib/start-infra.sh

# Start application if not running
./operator/lib/start-app.sh

# Verify everything is ready
kg health
```

**Common kg CLI Operations:**
```bash
# View platform status
kg database stats
kg admin status

# Search concepts
kg search query "recursive depth"
kg search details <concept-id>

# Ingest documents
kg ingest file -o "My Ontology" document.txt
kg ingest url -o "Research" https://example.com/article.html

# Manage ontologies
kg ontology list
kg ontology stats "My Ontology"

# Manage API keys and configuration
kg admin embedding list
kg admin extraction info
```

**Stopping Services:**
```bash
# Stop services (keeps data)
./operator/lib/stop.sh

# Complete teardown (removes all data and volumes)
./operator/lib/teardown.sh

# Teardown but keep .env secrets
./operator/lib/teardown.sh --keep-env
```

**Checking Logs:**
```bash
docker logs kg-api-dev                   # API server logs
docker logs knowledge-graph-postgres     # Database logs
docker logs kg-web-dev                   # Web app logs
```

### Resetting Database (Clean State)

When testing or after breaking changes, you can completely reset:

```bash
# 1. Complete teardown
./operator/lib/teardown.sh --keep-env

# 2. Start fresh
./operator/lib/start-infra.sh

# 3. Reconfigure (admin, AI provider, embeddings, API keys)
docker exec -it kg-operator python /workspace/operator/configure.py admin
docker exec kg-operator python /workspace/operator/configure.py ai-provider openai --model gpt-4o
docker exec kg-operator python /workspace/operator/configure.py embedding 2
docker exec -it kg-operator python /workspace/operator/configure.py api-key openai

# 4. Start application
./operator/lib/start-app.sh

# 5. Verify
kg database stats
```

### Making Changes

**When modifying AI extraction:**
1. Edit `src/api/lib/ai_providers.py` or `src/api/lib/llm_extractor.py`
2. Restart API: `cd docker && docker-compose restart api`
3. Test: `docker exec kg-operator python /workspace/operator/admin/extraction_test.py`
4. Test ingestion: `kg ingest file -o "Test" test-file.txt`

**When modifying database schema:**
1. Create new migration file: `schema/migrations/NNN_descriptive_name.sql`
2. Restart database (migrations auto-apply): `cd docker && docker-compose restart postgres`
3. Verify: `docker exec knowledge-graph-postgres psql -U admin -d knowledge_graph -c "\dt"`
4. **Important**: Migrations are applied automatically by `start-infra.sh` - never apply manually

**When modifying API endpoints:**
1. Edit files in `src/api/routes/`
2. Restart API: `cd docker && docker-compose restart api`
3. Test with kg CLI or curl

**When modifying kg CLI:**
1. Edit files in `client/src/cli/`
2. Rebuild: `cd client && npm run build`
3. Reinstall: `cd client && ./install.sh`
4. Test: `kg <command>`

**When modifying web app:**
1. Edit files in `web/`
2. Rebuild: `cd docker && docker-compose restart web`
3. Test: Open `http://localhost:3000`

**When modifying operator configuration:**
1. Edit `operator/configure.py` or `operator/admin/` scripts
2. Restart operator: `cd docker && docker-compose restart operator`
3. Test: `docker exec kg-operator python /workspace/operator/configure.py status`

## Key Concepts

### Concept Extraction Flow

1. **Submit** document via kg CLI â†’ POST `/ingest` endpoint
2. **Job created** with cost estimate â†’ Requires approval (ADR-014)
3. **Chunk** document into semantic chunks (~1000 words)
4. **Extract** concepts using LLM (GPT-4 or Claude) per chunk
5. **Match** against existing concepts via vector similarity
6. **Upsert** to Apache AGE with relationships
7. **Stream** progress updates via job status endpoint

### Graph Data Model

```cypher
// Nodes
(:Concept {concept_id, label, embedding, search_terms, description})
(:Source {source_id, document, paragraph, full_text})
(:Instance {instance_id, quote})

// Relationships
(:Concept)-[:APPEARS_IN]->(:Source)
(:Concept)-[:EVIDENCED_BY]->(:Instance)
(:Instance)-[:FROM_SOURCE]->(:Source)
(:Concept)-[:IMPLIES|SUPPORTS|CONTRADICTS|ENABLES]->(:Concept)
```

### AI Provider System

**Available Providers:**
- **OpenAI** - Cloud API (GPT-4o, GPT-4o-mini)
- **Anthropic** - Cloud API (Claude Sonnet 4, Claude 3.5 Sonnet)
- **Ollama** - Local inference (Mistral, Llama, Qwen, etc.) - ADR-042

**Configuration via Operator:**
```bash
# List available extraction providers and models
docker exec kg-operator python /workspace/operator/configure.py ai-provider --help

# Set OpenAI
docker exec kg-operator python /workspace/operator/configure.py ai-provider openai --model gpt-4o

# Set Anthropic
docker exec kg-operator python /workspace/operator/configure.py ai-provider anthropic --model claude-sonnet-4-20250514

# Set Ollama (requires Ollama container running)
docker exec kg-operator python /workspace/operator/configure.py ai-provider ollama --model mistral:7b-instruct

# Store API key (encrypted in database)
docker exec -it kg-operator python /workspace/operator/configure.py api-key openai

# Test extraction
docker exec kg-operator python /workspace/operator/admin/extraction_test.py
```

**Embedding Providers:**
```bash
# List available embedding profiles
docker exec kg-operator python /workspace/operator/configure.py embedding

# Typical output:
#   [1] âœ“ ACTIVE   openai   - text-embedding-3-small (1536 dims, float32)
#   [2]            local    - nomic-ai/nomic-embed-text-v1.5 (768 dims, float16, cpu)

# Activate a profile (by ID)
docker exec kg-operator python /workspace/operator/configure.py embedding 2
```

**Resource Management (ADR-043):**
When using local inference with Ollama + local embeddings on single-GPU systems, the system automatically manages VRAM contention:
- **Sufficient VRAM (>500MB free):** Embeddings run on GPU (~1-2ms per concept)
- **VRAM contention (<500MB free):** Embeddings fall back to CPU (~5-10ms per concept)
- **Performance impact:** ~100ms per chunk (negligible in 2-3 minute extraction jobs)
- **User notification:** Clear warning logs when CPU fallback activated

## Query Safety & GraphQueryFacade

**ADR-048** introduces namespace safety to prevent catastrophic collisions when vocabulary metadata moves to the graph alongside concepts.

### The Problem

Without explicit labels, queries can operate on wrong namespace:

```python
# âŒ UNSAFE: Will count ALL nodes (concepts + vocabulary)
client._execute_cypher("MATCH (n) RETURN count(n)")

# âŒ UNSAFE: Will delete vocabulary nodes too!
client._execute_cypher("MATCH (n) DELETE n")
```

### The Solution: GraphQueryFacade

Use `client.facade` for namespace-safe queries:

```python
from src.api.lib.age_client import AGEClient

client = AGEClient()

# âœ… SAFE: Only counts concept nodes
concept_count = client.facade.count_concepts()

# âœ… SAFE: Only matches concepts
concepts = client.facade.match_concepts(
    where="c.label =~ '(?i).*recursive.*'",
    limit=10
)

# âœ… SAFE: Only matches vocabulary types
vocab_types = client.facade.match_vocab_types(
    where="v.is_active = true"
)

# âœ… SAFE: Namespace-aware statistics
stats = client.facade.get_graph_stats()
```

### Facade Methods

**Concept Namespace:**
- `match_concepts(where, params, limit)` - Match :Concept nodes
- `match_concept_relationships(rel_types, where)` - Match concept edges
- `count_concepts(where, params)` - Count concepts
- `match_sources(where, params, limit)` - Match :Source nodes
- `match_instances(where, params, limit)` - Match :Instance nodes

**Vocabulary Namespace:**
- `match_vocab_types(where, params, limit)` - Match :VocabType nodes
- `match_vocab_categories(where, params)` - Match :VocabCategory nodes
- `find_vocabulary_synonyms(min_similarity, category)` - Find synonyms
- `count_vocab_types(where, params)` - Count vocabulary types

**Utilities:**
- `get_graph_stats()` - Namespace-aware statistics
- `execute_raw(query, params, namespace)` - Escape hatch for complex queries
- `get_audit_stats()` - Query safety metrics

### Query Linter

CI enforces query safety via linter:

```bash
# Run locally (via operator container)
docker exec kg-operator python /workspace/operator/diagnostics/lint_queries.py --verbose

# Check specific paths
docker exec kg-operator python /workspace/operator/diagnostics/lint_queries.py /workspace/src/api/routes /workspace/src/api/workers
```

**Current baseline:** 3 unsafe queries (documented in `docs/architecture/QUERY_SAFETY_BASELINE.md`)

### Development Guidelines

**When writing new code:**
1. Always use `client.facade` for graph queries
2. Never use bare `MATCH (n)` without explicit label
3. Run linter before committing: `docker exec kg-operator python /workspace/operator/diagnostics/lint_queries.py`

**When fixing unsafe queries:**
```python
# Before (unsafe)
results = client._execute_cypher(
    "MATCH (n) WHERE n.property = $value RETURN n",
    params={"value": "foo"}
)

# After (safe)
results = client.facade.match_concepts(
    where="c.property = $value",
    params={"value": "foo"}
)
```

## Common Tasks

### View Platform Configuration

```bash
# See all configuration status
docker exec kg-operator python /workspace/operator/configure.py status

# Output example:
# ğŸ“Š Platform Configuration Status
# Admin users: 1
# AI Extraction: openai / gpt-4o
# Embedding: local / nomic-ai/nomic-embed-text-v1.5 (768 dims)
# API Keys: openai
```

### Manage API Keys

```bash
# Store encrypted API key
docker exec -it kg-operator python /workspace/operator/configure.py api-key openai

# View stored keys (hashes only)
docker exec kg-operator python /workspace/operator/admin/manage_api_keys.py list

# Delete API key
docker exec kg-operator python /workspace/operator/admin/manage_api_keys.py delete openai
```

### Add a New AI Provider

1. Create class extending `AIProvider` in `src/api/lib/ai_providers.py`
2. Implement required methods:
   - `extract_concepts()`
   - `generate_embedding()`
   - `validate_api_key()`
   - `list_available_models()`
3. Update `get_provider()` factory function in `src/api/lib/ai_providers.py`
4. Add configuration option in `operator/configure.py`
5. Test: `docker exec kg-operator python /workspace/operator/admin/extraction_test.py`

### Add a New API Endpoint

1. Create route handler in `src/api/routes/` (e.g., `queries.py`)
2. Add request/response Pydantic models in route file
3. Implement AGEClient method in `src/api/lib/age_client.py`
4. Add endpoint to router in `src/api/main.py`
5. Restart API: `cd docker && docker-compose restart api`
6. Test with curl or kg CLI

### Add a New kg CLI Command

1. Create command file in `client/src/cli/` (e.g., `search.ts`)
2. Add client method in `client/src/api/client.ts`
3. Register command in `client/src/index.ts`
4. Rebuild: `cd client && npm run build`
5. Reinstall: `cd client && ./install.sh`
6. Test: `kg <new-command>`

### Add New Database Migration

1. Create migration file: `schema/migrations/NNN_descriptive_name.sql`
   - Use next sequential number (check existing migrations)
   - Follow existing migration format
2. Migration auto-applies on next database start
3. Verify: `docker exec knowledge-graph-postgres psql -U admin -d knowledge_graph -c "\dt"`

### Create a New ADR (Architecture Decision Record)

When making significant architectural decisions:

1. Create new ADR file: `docs/architecture/ADR-###-descriptive-name.md`
   - Use the next sequential number (check existing ADRs)
   - Follow the format from existing ADRs
   - Include: Status, Date, Context, Decision, Consequences, Alternatives Considered
2. **IMPORTANT:** Update `docs/architecture/ARCHITECTURE_DECISIONS.md`
   - Add new entry to the ADR Index table with title, status, and brief summary
   - Update "Last Updated" date
   - This file serves as the master index for all ADRs
3. Reference the new ADR in related documentation:
   - Update `docs/README.md` if it's a major user-facing change
   - Link from related ADRs using "Related ADRs" section
   - Update CLAUDE.md if it affects development workflow

## Troubleshooting

### Infrastructure Won't Start

```bash
# Check container status
docker ps -a

# Check logs
docker logs knowledge-graph-postgres
docker logs knowledge-graph-garage
docker logs kg-operator

# Check if .env exists and has secrets
cat .env | grep -E "ENCRYPTION_KEY|POSTGRES_PASSWORD|OAUTH_SIGNING_KEY"

# Regenerate secrets if missing
./operator/lib/init-secrets.sh --dev

# Complete restart
./operator/lib/teardown.sh --keep-env
./operator/lib/start-infra.sh
```

### API Server Issues

```bash
# Check API status
curl http://localhost:8000/health
kg health

# Check API logs
docker logs kg-api-dev

# Check if API can connect to database
docker exec kg-api-dev python -c "from src.api.lib.age_client import AGEClient; client = AGEClient(); print(client.get_statistics())"

# Restart API
cd docker && docker-compose restart api

# Check API configuration
docker exec kg-operator python /workspace/operator/configure.py status
```

### Database Connection Issues

```bash
# Check postgres container
docker ps -a | grep postgres

# Check postgres logs
docker logs knowledge-graph-postgres

# Check database exists
docker exec knowledge-graph-postgres psql -U admin -l

# Check AGE extension loaded
docker exec knowledge-graph-postgres psql -U admin -d knowledge_graph -c "\dx"

# Check tables exist
docker exec knowledge-graph-postgres psql -U admin -d knowledge_graph -c "\dt"

# Check migrations applied
docker exec knowledge-graph-postgres psql -U admin -d knowledge_graph -c "SELECT * FROM schema_migrations ORDER BY applied_at;"
```

### Configuration Issues

```bash
# Check platform configuration
docker exec kg-operator python /workspace/operator/configure.py status

# Test AI extraction
docker exec kg-operator python /workspace/operator/admin/extraction_test.py

# List API keys (hashes only)
docker exec kg-operator python /workspace/operator/admin/manage_api_keys.py list

# List embedding profiles
docker exec kg-operator python /workspace/operator/configure.py embedding
```

### kg CLI Issues

```bash
# Check kg CLI installed
which kg
kg --version

# Check API connection
kg health

# Reinstall kg CLI
cd client
npm install
npm run build
./install.sh
```

### Web App Issues

```bash
# Check web container
docker logs kg-web-dev

# Check web app running
curl http://localhost:3000

# Restart web app
cd docker && docker-compose restart web

# Check web app environment
docker exec kg-web-dev env | grep API_URL
```

## Code Style Guidelines

### Python (API Server)
- Use type hints for all functions
- Modular functions (<50 lines preferred)
- Package imports: `from src.api.lib.module import func`
- FastAPI route handlers in `src/api/routes/`
- Pydantic models for request/response validation

### TypeScript (kg CLI + MCP)
- Async/await for HTTP API calls
- Type interfaces for API request/response models
- Commander.js for CLI argument parsing
- Error handling with try/catch and colored output
- Axios client for REST API communication

### Shell Scripts (Operator)
- Use `set -e` for error handling
- Color codes for output clarity
- Validate prerequisites before running
- Consistent output format (â†’ for actions, âœ“ for success, âœ— for errors)

### React (Web App)
- Functional components with hooks
- TypeScript for type safety
- Component composition over inheritance
- Tailwind CSS for styling

## Testing Strategy

### Automated Tests

Development-time unit and integration tests:

```bash
# Run all tests (API + linters)
./scripts/development/test/all.sh

# Run API tests only
./scripts/development/test/api.sh

# Run linters only
./scripts/development/test/lint.sh

# Quick mode (skip coverage)
./scripts/development/test/all.sh --quick

# Pass arguments to pytest
./scripts/development/test/api.sh -v -k test_concept_extraction
```

**Note:** Test scripts automatically activate Python venv if needed. They test the API codebase, not the running containers.

### Manual Verification

```bash
# Check containers running
docker ps --format "table {{.Names}}\t{{.Status}}"

# Check platform configuration
kg admin status
docker exec kg-operator python /workspace/operator/configure.py status

# Test API health
kg health

# Test database connectivity
kg database stats

# Test ingestion pipeline
kg ingest file -o "Test" test-document.txt
kg database stats  # Verify concepts were created

# Test web app
open http://localhost:3000
```

## Performance Considerations

### Ingestion Speed
- LLM calls are slowest part (~2-5s per chunk)
- Job approval workflow (ADR-014) provides cost estimates
- Smart chunking optimizes chunk boundaries (~1000 words)
- Background job processing via FastAPI scheduler

### Query Performance
- Vector search: Python numpy cosine similarity (full scan)
- Graph traversal: AGE Cypher queries, limit depth to avoid explosion
- REST API adds ~10-50ms overhead vs direct DB queries
- Consider pgvector extension for faster vector search at scale

## Security Notes

- **Infrastructure Secrets (.env)**: Generated by `init-secrets.sh`, never edit manually
  - `ENCRYPTION_KEY` - Fernet key for encrypting API keys at rest
  - `OAUTH_SIGNING_KEY` - JWT token signing key
  - `POSTGRES_PASSWORD` - Database password
  - `GARAGE_RPC_SECRET` - Garage cluster secret
  - `INTERNAL_KEY_SERVICE_SECRET` - Internal service authorization token (ADR-031)
- **Application Configuration**: Stored encrypted in PostgreSQL (ADR-031)
  - OpenAI/Anthropic API keys
  - Garage S3 credentials
  - Admin user passwords
- **API Server**: No authentication by default - add if exposing publicly
- **kg CLI**: Communicates with localhost:8000 by default
- **MCP Server**: Runs locally via Claude Desktop, no external exposure
- **Docker**: Containers on isolated network

## Resources

### Graph Database & Query Language
- Apache AGE: https://age.apache.org/
- AGE Manual: https://age.apache.org/age-manual/master/intro/overview.html
- openCypher: https://opencypher.org/
- ISO/IEC 39075 GQL Standard: https://www.iso.org/standard/76120.html
- openCypher Language Reference: https://s3.amazonaws.com/artifacts.opencypher.org/openCypher9.pdf

### Frameworks & APIs
- FastAPI: https://fastapi.tiangolo.com/
- MCP Protocol: https://spec.modelcontextprotocol.io/
- OpenAI API: https://platform.openai.com/docs
- Anthropic API: https://docs.anthropic.com/

### Architecture
- See `docs/architecture/ARCHITECTURE_DECISIONS.md` for full ADR index
- See `docs/` for complete documentation
