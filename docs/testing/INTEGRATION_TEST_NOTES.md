# Integration Test Notes - Working Commands & Observations

**Branch:** `refactor/embedding-grounding-system`
**Date Started:** 2025-01-26
**Purpose:** Document verified working commands and observations during manual integration testing

---

## Phase 1: Cold Start & Schema Validation

### Database Reset
‚úÖ **Command:** `kg admin reset`
- User must hold Enter for 3 seconds (prevents accidental automation)
- Requires authentication (username: admin)
- Successfully stops containers, deletes database, removes volumes, restarts with clean database
- Re-initializes AGE schema automatically

**What `kg admin reset` DOES clear:**
- Graph tables (concepts, sources, instances, relationships)
- Vocabulary graph (all custom vocabulary entries)
- User accounts (admin account cleared)

**What `kg admin reset` DOES NOT clear:**
- OpenAI/Anthropic API keys (persisted in database)
- Embedding configurations (persisted)

**Post-Reset State:**
```
Schema Validation:
  Constraints: 3/3 (PostgreSQL schemas: kg_api, kg_auth, kg_logs)
  Vector Index: Yes (AGE graph exists)
  Nodes: 0
  Test Passed: Yes
```

**‚ö†Ô∏è Important Behavior:**
- After reset, if API server is running, it will attempt to generate embeddings for vocabulary prototypes
- It will use persisted API keys (not cleared by reset)
- However, user accounting is cleared, so authentication fails
- This triggers need to re-run `scripts/initialize-auth.sh`

### Database Statistics
‚úÖ **Command:** `kg database stats`
- Shows 0 concepts, 0 sources, 0 instances, 0 relationships after reset
- Clean state confirmed

### Ontology List
‚úÖ **Command:** `kg ontology list`
- Shows "No ontologies found" after reset (expected)

### Vocabulary Status
‚úÖ **Command:** `kg vocab status`
- 30 builtin relationship prototypes initialized automatically after reset
- Zone: COMFORT (healthy state)
- Aggressiveness: 0.0%
- 0 custom types (only builtins)
- 10 categories
- Builtin types include: SUPPORTS, CONTRADICTS, ENABLES, etc.

### Embedding Configuration
‚úÖ **Command:** `kg admin embedding list`
- Shows all embedding configurations
- Active configuration marked with "‚úì ACTIVE"
- Protection status visible (üîí delete-protected, üîê change-protected)

**Current Configuration (after reset):**
- **Active:** OpenAI text-embedding-3-small (1536 dimensions) - protected
- **Inactive:** Local nomic-embed-text-v1.5 (768 dimensions)

### Authentication & AI Provider Initialization
‚úÖ **Script:** `scripts/initialize-auth.sh`

**Key Characteristics:**
- **Does NOT require API server running** - operates directly on database
- Can be used in Docker container initialization
- Interactive script with password validation

**What it does:**
1. Creates/resets admin user account with password
2. Generates JWT secret key (saved to .env)
3. Generates encryption key for API keys (Fernet AES-128, saved to .env)
4. Offers to configure AI provider (OpenAI or Anthropic)
5. Validates and encrypts API keys at rest
6. Initializes AI extraction configuration with default model
7. Resets active embedder to chosen provider

**Post-Initialization State:**
- Admin account ready with chosen password
- JWT secret in .env
- Encryption key in .env
- API keys encrypted in database
- AI provider configured (e.g., OpenAI/gpt-4o)
- Active embedder set to chosen provider

**Use Cases:**
- Initial setup after fresh database
- Recovery after `kg admin reset`
- Docker container first-run initialization
- Resetting admin password
- Changing AI provider

---

## Key Learnings

1. **Correct tool for embedding config:** `kg admin embedding` (not `kg admin extraction`)
2. **Database reset behavior:**
   - Clears: graph data, vocabulary graph, user accounts
   - Preserves: API keys, embedding configurations
   - Rebuilds: builtin vocabulary prototypes (30 entries)
3. **Proper cold start sequence:**
   - Step 1: `kg admin reset` (clears graph data)
   - Step 2: Restart API server (picks up clean state)
   - Step 3: `scripts/initialize-auth.sh` (sets up auth + AI provider)
   - Step 4: Ready to ingest content
4. **Hot reload mode:** API server can run in hot reload mode during testing
5. **Protection flags:** Active embedding configurations are protected by default
6. **initialize-auth.sh independence:** Script operates directly on database, doesn't require API server running

---

## Phase 1 Edge Case Testing

### Invalid API Key on Cold Start
‚úÖ **Scenario:** Start API server with invalid OpenAI API key after `kg admin reset`

**Expected Behavior:** Graceful degradation (system starts but vocabulary embeddings fail)

**Observed Behavior:**
- API server starts successfully
- EmbeddingWorker attempts to generate embeddings for 30 builtin vocabulary types
- All 30 embedding generations fail with 401 errors
- Each failure logged as ERROR with clear message: "Incorrect API key provided"
- Cold start completes: "0/30 builtin types initialized in ~2800ms"
- Warning logged: "30 types failed during cold start"
- API server reports ready: "üéâ API ready!"

**Result:** ‚úÖ **PASS - System fails gracefully**
- API server remains operational
- User can fix API key via `scripts/initialize-auth.sh` or API endpoints
- No crash or hang
- Clear error messages in logs

**Key Finding:** The system doesn't require valid API keys to start - this allows recovery from configuration errors without needing to restart services.

### Missing Embeddings After Invalid Key Recovery
‚úÖ **Scenario:** After cold start fails with invalid key (0/30 initialized), user runs `scripts/initialize-auth.sh` with valid key and restarts API

**Observed Behavior:**
- System checks `system_initialization_status` table: `initialized = true`
- Logs: "Cold start already completed, skipping"
- **No embeddings actually exist in vocabulary graph**
- API reports: "‚úì Builtin vocabulary embeddings already initialized"
- System operates but grounding calculations will fail

**Root Cause:**
- `system_initialization_status` marks initialization as "complete" even when 0/30 types succeed
- Restart logic only checks boolean flag, not actual embedding existence
- No validation that embeddings actually exist in graph

**Improvement Needed:**
1. **Startup validation worker:**
   - Query vocabulary graph nodes to count embeddings that actually exist
   - Compare against expected count (30 builtins)
   - If mismatch, log WARNING and mark system as degraded
2. **Health endpoint enhancement:**
   - Add vocabulary embedding status to `/health`
   - Return: `{ "vocabulary_embeddings": { "expected": 30, "actual": 0, "status": "degraded" }}`
3. **Recovery mechanism:**
   - Allow manual re-initialization trigger (API endpoint or CLI command)
   - Or: automatically retry if actual count < expected count on startup

**Current Workaround:**
- Run `kg admin reset` again with valid API key configured
- Or: Manually update `system_initialization_status` to `initialized = false`

---

## Vocabulary Storage Architecture - VERIFIED ‚úÖ

### Investigation Result
Vocabulary embeddings are stored in **`kg_api.relationship_vocabulary` PostgreSQL table**, NOT as graph nodes. **This is the correct, intended design per ADR-045/046.**

**Evidence:**
- Only 1 AGE graph exists: `knowledge_graph` (for concepts, not vocabulary)
- No `VocabularyType` label in graph
- All ADRs (044, 045, 046) specify table-based approach
- Migrations 011 & 012 modify the table, not graph structure

**Conclusion:** Table-based design is complete and working correctly.

---

## Code Duplication Fix: Unified Embedding Generation Path ‚úÖ

### Issue Found
Two separate code paths for generating vocabulary embeddings:
1. **Cold start:** `EmbeddingWorker.initialize_builtin_embeddings()` - logs job_id and progress
2. **CLI command:** `AGEClient.generate_vocabulary_embeddings()` - no logging, separate implementation

**Impact:** Duplicate logic, inconsistent logging, violates DRY principle

### Fix Applied
**File:** `src/api/routes/vocabulary.py:483-558`
- Updated `/vocabulary/generate-embeddings` endpoint to use `EmbeddingWorker`
- Now calls `initialize_builtin_embeddings()` (same as cold start)
- Removed obsolete `AGEClient.generate_vocabulary_embeddings()` method

**File:** `src/api/lib/age_client.py`
- Deleted 118 lines of duplicate embedding generation code (lines 1614-1731)

**Result:**
- ‚úÖ Single code path for vocabulary embeddings
- ‚úÖ Consistent logging with job_id tracking
- ‚úÖ CLI command shows same helpful output as cold start
- ‚úÖ ~118 lines of duplicate code removed

**Verification:**
```bash
kg vocab generate-embeddings
```

**Log output:**
```
2025-10-26 11:02:08 | INFO | src.api.services.embedding_worker:initialize_builtin_embeddings:125 | [2e685f7f-a044-405b-8c0f-5cd5cdd6008c] Starting cold start: Initializing builtin vocabulary embeddings
2025-10-26 11:02:08 | INFO | src.api.services.embedding_worker:initialize_builtin_embeddings:130 | [2e685f7f-a044-405b-8c0f-5cd5cdd6008c] Cold start already completed, skipping
```

**Status:** FIXED ‚úÖ

---

## CLI Display Bug: Hardcoded Embedding Provider ‚úÖ

### Issue Found
`kg vocab generate-embeddings` always displayed "Generating embeddings via OpenAI API..." regardless of active embedding configuration.

**Evidence:**
```bash
kg admin embedding list  # Shows active: local / nomic-ai/nomic-embed-text-v1.5
kg vocab generate-embeddings  # Incorrectly showed: "via OpenAI API..."
```

### Fix Applied
**File:** `client/src/cli/vocabulary.ts:300-306`
- Dynamically fetch active embedding config via `client.getEmbeddingConfig()`
- Display correct provider name and model
- Updated message format: `"Generating embeddings via {provider} ({model})..."`

**Result:**
```bash
kg vocab generate-embeddings
# Now correctly shows: "Generating embeddings via local embeddings (nomic-ai/nomic-embed-text-v1.5)..."
```

**Status:** FIXED ‚úÖ

---

## Hot Reload Not Resetting EmbeddingWorker ‚úÖ

### Issue Found
After running `kg admin embedding reload`, the EmbeddingWorker singleton continued using the old provider. Switching from local (768D) ‚Üí OpenAI (1536D) resulted in embeddings still being generated at 768D.

**Root Cause:**
- Hot reload endpoint called `reload_embedding_model_manager()` but not `reset_embedding_worker()`
- EmbeddingWorker is a singleton initialized once on first use
- Subsequent calls to `get_embedding_worker()` returned cached instance with old provider

### Fix Applied
**File:** `src/api/routes/embedding.py:222-229`
- Added call to `reset_embedding_worker()` in hot reload endpoint
- EmbeddingWorker singleton now resets when config changes
- Next `get_embedding_worker()` call creates fresh instance with new provider

**Verification:**
```bash
kg admin embedding activate 1  # Switch to OpenAI (1536D)
kg admin embedding reload       # Hot reload
kg vocab generate-embeddings --force

# SQL verification:
SELECT jsonb_array_length(embedding) FROM kg_api.relationship_vocabulary LIMIT 1;
# Returns: 1536 ‚úÖ (was 768 before fix)
```

**Status:** FIXED ‚úÖ

---

## Summary of Fixes

During Phase 1 integration testing, we discovered and fixed:

1. ‚úÖ **Vocabulary storage architecture** - Table-based is correct design (not a bug)
2. ‚úÖ **Code duplication** - Unified embedding generation path, removed 118 lines of duplicate code
3. ‚úÖ **CLI display bug** - Dynamically fetch and display actual active embedding provider
4. ‚úÖ **Cold start detection** - Moved from EmbeddingWorker to API startup logic
5. ‚úÖ **Hot reload** - Now resets EmbeddingWorker singleton to pick up provider changes

**Key Learnings:**
- Cold start logic belongs in startup code, not worker methods
- Singletons must be reset when config changes
- User-initiated commands should bypass cold start checks

---

## Phase 2: Content Ingestion - SUCCESS ‚úÖ

### Test Configuration
- **Ontology:** SignalFabric
- **Files ingested:** 4
- **Embedding provider:** local (nomic-ai/nomic-embed-text-v1.5, 768D)
- **All 4 jobs completed successfully**

### Results
```bash
kg database stats
```

**Nodes Created:**
- Concepts: 63
- Sources: 9 (document chunks)
- Instances: 81 (evidence quotes)

**Relationships:**
- Total: 300
- Types discovered: 20 (15 builtins + 5 custom)
- Top types: SUPPORTS (10), PART_OF (8), CONTAINS (6), CONTRASTS_WITH (5), REQUIRES (5)

**Vocabulary Expansion:**
- Before: 30 builtin types
- After: 35 total (5 new custom types)
- Zone: COMFORT (5.7% aggressiveness)
- Categories: 11

### Verification Tests

**1. Search Functionality ‚úÖ**
```bash
kg search query "signal" --limit 5
```
- Found: "Signal Fabric" concept (73.9% similarity)
- Evidence: 8 instances
- **Grounding: ‚ö° Moderate (0.380, 38%)** ‚Üê Confirmed working!

**2. Grounding Calculations ‚úÖ**
- Grounding strength calculated and displayed correctly
- Format: "‚ö° Moderate (0.380, 38%)"
- Semantic similarity search working (requires embeddings)

**3. Evidence Display ‚úÖ**
- Instance counts shown in search results
- Evidence properly linked to concepts

### Key Findings
1. ‚úÖ Local embeddings (768D) work correctly for ingestion
2. ‚úÖ LLM extraction discovered 5 new relationship types
3. ‚úÖ Grounding calculations functional
4. ‚úÖ Semantic search working via embeddings
5. ‚úÖ Vocabulary management staying in COMFORT zone

**Status:** Phase 2 COMPLETE ‚úÖ

### Graph Evolution Test: Incremental Ingestion Impact

Tested the same query before and after ingesting a 5th document to observe how the graph evolves:

**Query:** `kg search connect "configuration management" "atlassian operator" --show-evidence`

**Before (4 documents):**
- From: Change Management (60.9% match)
- To: Atlassian (86.1% match)
- Result: 3 paths, all **4 hops** long
- Path: Change Management ‚Üí Signal Fabric ‚Üí Govern-Agility ‚Üí Cprime ‚Üí Atlassian

**After (+ Atlassian Platform Operations document):**
- From: Ongoing Configuration Management (89.5% match) ‚Üê MORE SPECIFIC
- To: atlassian-operator (96.9% match) ‚Üê NEARLY PERFECT
- Result: **1 path, only 1 hop** (DIRECT CONNECTION!)
- Path: Ongoing Configuration Management ‚ÜíENABLES‚Üí atlassian-operator
- Grounding: Strong (100%) ‚Üí Weak (27%)

**Key Findings:**
1. ‚úÖ **Semantic search improved**: Better concept matches as vocabulary grows
2. ‚úÖ **Graph evolution**: New document created direct relationship (1 hop vs 4 hops)
3. ‚úÖ **Concept specificity**: System prefers "Ongoing Configuration Management" over generic "Change Management"
4. ‚úÖ **Exact term extraction**: "atlassian-operator" extracted as distinct concept
5. ‚úÖ **Path optimization**: System found shorter, more specific path automatically
6. ‚úÖ **Grounding on new concepts**: Both new concepts show grounding calculations (100%, 27%)

**Conclusion:** The knowledge graph correctly evolves with new information, creating more direct and semantically accurate relationships as content is ingested.

---

## Phase 3: CLI Query Testing with --json Flag

Testing all CLI commands with `--json` flag to verify structured output for MCP server integration.

### Test 3.1: Search Query with JSON

**Command:** `kg search query "signal fabric" --limit 3 --json`

**Results:**
```json
{
  "query": "signal fabric",
  "count": 1,
  "results": [{
    "concept_id": "marketopp.md_chunk1_6875584f",
    "label": "Signal Fabric",
    "score": 1,
    "grounding_strength": 0.37990068523214476,  ‚Üê ‚úÖ Present
    "evidence_count": 8,
    "sample_evidence": null  ‚Üê Without --show-evidence flag
  }]
}
```

**Observations:**
- ‚úÖ JSON output is well-structured
- ‚úÖ `grounding_strength` included in results
- ‚úÖ `evidence_count` shows number of supporting quotes
- ‚úÖ Threshold information included (threshold_used, below_threshold_count)
- ‚ö†Ô∏è `sample_evidence` is null without `--show-evidence` flag

### Test 3.2: Search Query with Evidence

**Command:** `kg search query "signal fabric" --limit 3 --show-evidence --json`

**Results:**
```json
{
  "results": [{
    "grounding_strength": 0.37990068523214476,
    "sample_evidence": [
      {
        "quote": "Signal Fabric as a consulting methodology",
        "document": "SignalFabric",
        "paragraph": 1,
        "source_id": "impllay.md_chunk1"
      }
      // ... more evidence
    ]
  }]
}
```

**Observations:**
- ‚úÖ `--show-evidence` populates `sample_evidence` array
- ‚úÖ Evidence includes quote, document, paragraph, source_id
- ‚úÖ Multiple evidence samples shown (up to 3 per concept)
- ‚úÖ Grounding strength + evidence together enable verification

### Test 3.3: Concept Details with JSON

**Command:** `kg search details marketopp.md_chunk1_6875584f --json`

**Results:**
```json
{
  "concept_id": "marketopp.md_chunk1_6875584f",
  "label": "Signal Fabric",
  "search_terms": ["Signal Fabric", "Signal-First Methodology", ...],
  "documents": ["SignalFabric"],
  "instances": [
    {
      "quote": "Signal Fabric provides the technical playbook...",
      "document": "SignalFabric",
      "paragraph": 1,
      "source_id": "govagilealign.md_chunk1",
      "full_text": "..." // Full paragraph context
    }
    // ... all 8 instances
  ]
}
```

**Observations:**
- ‚úÖ Complete concept details in JSON
- ‚úÖ All evidence instances with full context
- ‚úÖ Search terms array for semantic matching
- ‚ö†Ô∏è `grounding_strength` not included in details output (may be intentional)

### Test 3.4: Connection Path with JSON

**Command:** `kg search connect "configuration management" "atlassian operator" --json`

**Results:**
```json
{
  "from_concept": {
    "id": "020-atlassian-platform-operations-compiler.md_chunk2_47df31a1",
    "label": "Ongoing Configuration Management"
  },
  "to_concept": {
    "id": "020-atlassian-platform-operations-compiler.md_chunk3_74477954",
    "label": "atlassian-operator"
  },
  "from_similarity": 0.8954896529153705,
  "to_similarity": 0.9689494130319128,
  "paths": [{
    "nodes": [
      {
        "id": "...",
        "label": "Ongoing Configuration Management",
        "grounding_strength": 1.0  ‚Üê ‚úÖ Present in path nodes
      },
      {
        "id": "...",
        "label": "atlassian-operator",
        "grounding_strength": 0.27202611556534745  ‚Üê ‚úÖ Present
      }
    ],
    "relationships": ["ENABLES"],
    "hops": 1
  }]
}
```

**Observations:**
- ‚úÖ Complete path information in JSON
- ‚úÖ `grounding_strength` included for each node in path
- ‚úÖ Relationship types shown
- ‚úÖ Similarity scores for matched concepts
- ‚úÖ Hop count for each path

### Test 3.5: Related Concepts with JSON

**Command:** `kg search related marketopp.md_chunk1_6875584f --depth 1 --json`

**Results:**
```json
{
  "concept_id": "marketopp.md_chunk1_6875584f",
  "max_depth": 1,
  "count": 19,
  "results": [
    {
      "concept_id": "marketopp.md_chunk1_1804a3be",
      "label": "AI and Data Quality",
      "distance": 1,
      "path_types": ["SUPPORTS"]
    }
    // ... 18 more
  ]
}
```

**Observations:**
- ‚úÖ List of related concepts with labels
- ‚úÖ Distance (hop count) from source concept
- ‚úÖ Relationship types as `path_types` array
- ‚ö†Ô∏è `grounding_strength` not included for related concepts (may be performance consideration)

### Phase 3 Summary

**What Works:**
1. ‚úÖ All CLI commands support `--json` flag
2. ‚úÖ Grounding strength included in search and connect results
3. ‚úÖ Evidence display works with `--show-evidence` flag
4. ‚úÖ JSON output is well-structured and parseable
5. ‚úÖ Complete metadata (similarity scores, hop counts, relationship types)

**Design Decisions Observed:**
- Details command focuses on evidence/instances, not grounding (grounding shown in search)
- Related concepts omit grounding (19 results would be verbose, performance consideration)
- Evidence sampling: Search shows 3 samples, details shows all instances

**MCP Integration Readiness:**
- ‚úÖ JSON output suitable for MCP server consumption
- ‚úÖ Grounding + evidence available for AI agents to assess concept reliability
- ‚úÖ All query types have structured output

**Status:** Phase 3 COMPLETE ‚úÖ

---

## Next Steps

- [x] Test content ingestion with local embedder
- [x] Verify grounding calculations work
- [x] **Phase 3:** Test CLI queries with --json flag
- [ ] **Phase 4:** Test MCP server formatted output
- [ ] **Phase 5:** Switch embedders and verify compatibility

---

*This document will be updated as we progress through integration testing.*
